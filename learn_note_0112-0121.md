# 20260112
1. 这里的rank = int(os.getenv("RANK", 0))
    world_size = int(os.getenv("WORLD_SIZE", 1))
    local_rank = int(os.getenv("LOCAL_RANK", 0))，world_size表示总共有多少张GPU，rank表示全局gpu编号，例如共有16张gpu,rank取值范围是0-15，local_rank是局部gpu编号，这里局部是只机器节点，一个节点上有8张gpu，每个节点上local_rank都是0-7的取值范围，这样理解对么？
2. torch.cuda.set_device(local_rank)
        dist.init_process_group(
            backend="nccl",
            init_method="env://",
            rank=rank,
            world_size=world_size)这是在做什么，对这两行代码需要理解的内容有哪些，在训练和推理中都需要这样的设置么？
3. dist.barrier()  # 同步所有进程，这里是在同步什么？init_method="env://",  # 从环境变量读取配置，这里一般都只传了主节点的IP和端口，也就是剩余次节点只知道主节点的信息，不知道彼此的通信地址，那在进行通信时都要通过主节点进行转发么？比如dist.broadcast()广播的时候，次节点a如何把要广播的内容传递给其他次节点
4. 详细介绍dist.all_reduce()时什么，以及Reduce-Scatter 和All-Gather是什么

# 20260121

## 吴恩达 Agentic AI

- 为什么agent很重要，如何让它高效  
  为什么很重要？看一个例子  
  gpt3.5编程正确率48%  
  gpt4编程正确率67%  
  在gpt上使用各种不同的agent工作流可以将编程水平提升到70%到95%的正确率  
  可以这样看，从gpt3.5到gpt4对大模型进行优化提升，编程能力从48%提升到67%  
  在gpt3.5上使用agent工作流，编程能力能达到70%+，比去进行高costly的模型优化带来的提升还要高  

- 好的agent工作流能提升大模型解决某种具体问题的能力  

- 4种agent设计模型:
    反思
    工具调用（包括代码执行）
    规划
    多agent协同
- 一些重要的点：
    设计端到端的工作流评估模块
    工作流组件评估模块
    错误分析
    建立主流大模型擅长的任务直觉（多用），多看别人写的prompt
    工作流的自主能力
- 简单来讲agent就是模仿人类在解决某个任务时的处理步骤
    先观察人类是如果完成某个任务的，都有哪些步骤，比如写一篇论文
    分析哪些步骤是大模型能独立完成的，进一步分析不能独立完成的步骤是否还能继续细化拆解

## Auto-CoT  
- 需要修改模型权重么？
- 阶段一中问题聚类阶段具体是怎么进行的
    哪些步骤是由用户完成的，
    哪些是由模型完成的？
    聚类这一操作是向模型发出指令由模型自己完成么？
    是否能让模型来完成聚类过程，如何设计流程？
- 阶段二中从每个cluster中选择代表题是谁选？用户还是模型？怎么选？
- 总结：Auto-CoT就是选择一些有代表性的问题，让模型生成思维链，要求生成的思维简洁、清晰、正确。如果生成的不符合标准，丢弃，然后换下一个问题。
- 好了，现在假设通过前面过程已经有5组符合标准的问题及对应的思维链了。然后呢？
- 把这5组示例与具体问题拼接，进行few-shot CoT